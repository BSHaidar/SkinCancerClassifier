{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "import sys\n",
    "sys.path.insert(0, '/Users/basselhaidar/Desktop/Final Project/SkinCancerClassifier/py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0719 09:31:44.914834 4498068928 deprecation_wrapper.py:119] From /Users/basselhaidar/Desktop/Final Project/SkinCancerClassifier/py/cnn_classifier.py:21: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from setup_images import create_img_dict, set_df, sns_countplot\n",
    "from cnn_classifier import *\n",
    "import pandas_profiling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images = 10015\n",
      "Check path of ISIC_0025030.jpg = ../skin-cancer-mnist-ham10000/HAM10000_images_part_1/ISIC_0025030.jpg\n"
     ]
    }
   ],
   "source": [
    "df = set_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pandas_profiling.ProfileReport(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns_countplot(df, 'category_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0718 15:40:28.120718 4488385984 deprecation_wrapper.py:119] From /anaconda3/envs/flatiron/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0718 15:40:28.122544 4488385984 deprecation_wrapper.py:119] From /anaconda3/envs/flatiron/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0718 15:40:28.124559 4488385984 deprecation_wrapper.py:119] From /anaconda3/envs/flatiron/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0718 15:40:28.147010 4488385984 deprecation_wrapper.py:119] From /anaconda3/envs/flatiron/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0718 15:40:28.167349 4488385984 deprecation_wrapper.py:119] From /anaconda3/envs/flatiron/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W0718 15:40:28.278049 4488385984 deprecation_wrapper.py:119] From /anaconda3/envs/flatiron/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 450, 600, 64)      1792      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 450, 600, 64)      256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 225, 300, 64)      0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4320000)           0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                138240032 \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 7)                 231       \n",
      "=================================================================\n",
      "Total params: 138,242,439\n",
      "Trainable params: 138,242,247\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "cnn = set_cnn_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 7 classes.\n",
      "Found 6415 images belonging to 7 classes.\n",
      "Found 1600 images belonging to 7 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0718 15:40:33.332879 4488385984 deprecation_wrapper.py:119] From /anaconda3/envs/flatiron/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0718 15:40:33.410459 4488385984 deprecation.py:323] From /anaconda3/envs/flatiron/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/24\n",
      "32/32 [==============================] - 14s 429ms/step - loss: 2.4930 - acc: 0.1875 - val_loss: 5.5406 - val_acc: 0.6562\n",
      "Epoch 2/24\n",
      "32/32 [==============================] - 10s 326ms/step - loss: 2.0302 - acc: 0.5625 - val_loss: 4.3308 - val_acc: 0.4688\n",
      "Epoch 3/24\n",
      "32/32 [==============================] - 10s 325ms/step - loss: 1.9128 - acc: 0.5938 - val_loss: 2.7474 - val_acc: 0.4688\n",
      "Epoch 4/24\n",
      "32/32 [==============================] - 11s 329ms/step - loss: 1.8181 - acc: 0.5938 - val_loss: 2.3466 - val_acc: 0.4062\n",
      "Epoch 5/24\n",
      "32/32 [==============================] - 11s 341ms/step - loss: 1.7624 - acc: 0.5938 - val_loss: 2.2300 - val_acc: 0.4375\n",
      "Epoch 6/24\n",
      "32/32 [==============================] - 11s 351ms/step - loss: 1.7306 - acc: 0.5938 - val_loss: 2.1921 - val_acc: 0.5000\n",
      "Epoch 7/24\n",
      "32/32 [==============================] - 10s 325ms/step - loss: 1.6923 - acc: 0.5938 - val_loss: 2.1938 - val_acc: 0.5000\n",
      "Epoch 8/24\n",
      "32/32 [==============================] - 11s 329ms/step - loss: 1.6649 - acc: 0.6250 - val_loss: 2.1930 - val_acc: 0.4688\n",
      "Epoch 9/24\n",
      "32/32 [==============================] - 11s 334ms/step - loss: 1.6353 - acc: 0.6250 - val_loss: 2.1845 - val_acc: 0.4688\n",
      "Epoch 10/24\n",
      "32/32 [==============================] - 11s 337ms/step - loss: 1.6071 - acc: 0.6250 - val_loss: 2.1751 - val_acc: 0.4688\n",
      "Epoch 11/24\n",
      "32/32 [==============================] - 11s 338ms/step - loss: 1.5807 - acc: 0.6562 - val_loss: 2.1551 - val_acc: 0.4688\n",
      "Epoch 12/24\n",
      "32/32 [==============================] - 11s 337ms/step - loss: 1.5560 - acc: 0.6250 - val_loss: 2.1492 - val_acc: 0.4688\n",
      "Epoch 13/24\n",
      "32/32 [==============================] - 11s 335ms/step - loss: 1.5294 - acc: 0.7188 - val_loss: 2.1335 - val_acc: 0.5000\n",
      "Epoch 14/24\n",
      "32/32 [==============================] - 11s 338ms/step - loss: 1.4988 - acc: 0.7188 - val_loss: 2.1357 - val_acc: 0.4688\n",
      "Epoch 15/24\n",
      "32/32 [==============================] - 11s 337ms/step - loss: 1.4694 - acc: 0.7188 - val_loss: 2.1192 - val_acc: 0.4688\n",
      "Epoch 16/24\n",
      "32/32 [==============================] - 11s 342ms/step - loss: 1.4380 - acc: 0.7500 - val_loss: 2.1176 - val_acc: 0.4688\n",
      "Epoch 17/24\n",
      "32/32 [==============================] - 11s 335ms/step - loss: 1.4074 - acc: 0.7500 - val_loss: 2.1060 - val_acc: 0.4688\n",
      "Epoch 18/24\n",
      "32/32 [==============================] - 12s 371ms/step - loss: 1.3847 - acc: 0.7500 - val_loss: 2.1065 - val_acc: 0.4688\n",
      "Epoch 19/24\n",
      "32/32 [==============================] - 11s 338ms/step - loss: 1.3696 - acc: 0.7500 - val_loss: 2.0898 - val_acc: 0.4688\n",
      "Epoch 20/24\n",
      "32/32 [==============================] - 11s 336ms/step - loss: 1.3450 - acc: 0.7500 - val_loss: 2.0926 - val_acc: 0.4688\n",
      "Epoch 21/24\n",
      "32/32 [==============================] - 12s 361ms/step - loss: 1.3234 - acc: 0.7500 - val_loss: 2.0435 - val_acc: 0.4688\n",
      "Epoch 22/24\n",
      "32/32 [==============================] - 11s 339ms/step - loss: 1.3051 - acc: 0.7500 - val_loss: 2.0419 - val_acc: 0.4688\n",
      "Epoch 23/24\n",
      "32/32 [==============================] - 11s 337ms/step - loss: 1.2759 - acc: 0.7500 - val_loss: 2.0075 - val_acc: 0.5000\n",
      "Epoch 24/24\n",
      "32/32 [==============================] - 11s 338ms/step - loss: 1.2563 - acc: 0.7500 - val_loss: 2.0013 - val_acc: 0.5000\n"
     ]
    }
   ],
   "source": [
    "images_test, labels_test = fit_cnn_model(cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0718 19:06:23.353774 4414420416 deprecation_wrapper.py:119] From /anaconda3/envs/flatiron/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0718 19:06:23.355603 4414420416 deprecation_wrapper.py:119] From /anaconda3/envs/flatiron/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0718 19:06:23.358042 4414420416 deprecation_wrapper.py:119] From /anaconda3/envs/flatiron/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0718 19:06:23.382852 4414420416 deprecation_wrapper.py:119] From /anaconda3/envs/flatiron/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0718 19:06:23.407685 4414420416 deprecation_wrapper.py:119] From /anaconda3/envs/flatiron/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W0718 19:06:23.542234 4414420416 deprecation_wrapper.py:119] From /anaconda3/envs/flatiron/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0718 19:06:23.548851 4414420416 deprecation.py:506] From /anaconda3/envs/flatiron/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 450, 600, 64)      1792      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 450, 600, 64)      256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 225, 300, 64)      0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 225, 300, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 223, 298, 32)      18464     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 223, 298, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 111, 149, 32)      0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 111, 149, 32)      0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 529248)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                16935968  \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 7)                 231       \n",
      "=================================================================\n",
      "Total params: 16,956,967\n",
      "Trainable params: 16,956,711\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "cnn2 = set_cnn_dropout_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 7 classes.\n",
      "Found 6415 images belonging to 7 classes.\n",
      "Found 1600 images belonging to 7 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0718 19:06:34.455914 4414420416 deprecation_wrapper.py:119] From /anaconda3/envs/flatiron/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0718 19:06:34.521924 4414420416 deprecation.py:323] From /anaconda3/envs/flatiron/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/100\n",
      "32/32 [==============================] - 15s 471ms/step - loss: 2.5598 - acc: 0.1875 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      "32/32 [==============================] - 14s 422ms/step - loss: 3.0933 - acc: 0.1250 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 3/100\n",
      "32/32 [==============================] - 13s 421ms/step - loss: 2.4031 - acc: 0.2188 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 4/100\n",
      "32/32 [==============================] - 13s 417ms/step - loss: 1.8375 - acc: 0.3750 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 5/100\n",
      "32/32 [==============================] - 13s 420ms/step - loss: 1.4196 - acc: 0.5312 - val_loss: 15.6910 - val_acc: 0.0000e+00\n",
      "Epoch 6/100\n",
      "32/32 [==============================] - 13s 421ms/step - loss: 1.1577 - acc: 0.6250 - val_loss: 15.2570 - val_acc: 0.0312\n",
      "Epoch 7/100\n",
      "32/32 [==============================] - 13s 420ms/step - loss: 0.9916 - acc: 0.6875 - val_loss: 13.9746 - val_acc: 0.0312\n",
      "Epoch 8/100\n",
      "32/32 [==============================] - 14s 432ms/step - loss: 0.8698 - acc: 0.7500 - val_loss: 12.6450 - val_acc: 0.0312\n",
      "Epoch 9/100\n",
      "32/32 [==============================] - 13s 417ms/step - loss: 0.7568 - acc: 0.7188 - val_loss: 11.3783 - val_acc: 0.0312\n",
      "Epoch 10/100\n",
      "32/32 [==============================] - 14s 427ms/step - loss: 0.6771 - acc: 0.7812 - val_loss: 10.2085 - val_acc: 0.1250\n",
      "Epoch 11/100\n",
      "32/32 [==============================] - 14s 424ms/step - loss: 0.6432 - acc: 0.7812 - val_loss: 8.6169 - val_acc: 0.2500\n",
      "Epoch 12/100\n",
      "32/32 [==============================] - 14s 424ms/step - loss: 0.6247 - acc: 0.7812 - val_loss: 7.0976 - val_acc: 0.3125\n",
      "Epoch 13/100\n",
      "32/32 [==============================] - 13s 417ms/step - loss: 0.5901 - acc: 0.7812 - val_loss: 5.8583 - val_acc: 0.4062\n",
      "Epoch 14/100\n",
      "32/32 [==============================] - 13s 418ms/step - loss: 0.5356 - acc: 0.7812 - val_loss: 4.9521 - val_acc: 0.4688\n",
      "Epoch 15/100\n",
      "32/32 [==============================] - 13s 421ms/step - loss: 0.4647 - acc: 0.7812 - val_loss: 4.3621 - val_acc: 0.5625\n",
      "Epoch 16/100\n",
      "32/32 [==============================] - 14s 427ms/step - loss: 0.3984 - acc: 0.7812 - val_loss: 4.0529 - val_acc: 0.6562\n",
      "Epoch 17/100\n",
      "32/32 [==============================] - 14s 451ms/step - loss: 0.3595 - acc: 0.9062 - val_loss: 3.9135 - val_acc: 0.6562\n",
      "Epoch 18/100\n",
      "32/32 [==============================] - 14s 434ms/step - loss: 0.3575 - acc: 0.8750 - val_loss: 3.8432 - val_acc: 0.6875\n",
      "Epoch 19/100\n",
      "32/32 [==============================] - 14s 425ms/step - loss: 0.3608 - acc: 0.8438 - val_loss: 3.8257 - val_acc: 0.6562\n",
      "Epoch 20/100\n",
      "32/32 [==============================] - 13s 417ms/step - loss: 0.3495 - acc: 0.8438 - val_loss: 3.8275 - val_acc: 0.6562\n",
      "Epoch 21/100\n",
      "32/32 [==============================] - 13s 416ms/step - loss: 0.3061 - acc: 0.9062 - val_loss: 3.8199 - val_acc: 0.6562\n",
      "Epoch 22/100\n",
      "32/32 [==============================] - 13s 419ms/step - loss: 0.2562 - acc: 0.9062 - val_loss: 3.7777 - val_acc: 0.6562\n",
      "Epoch 23/100\n",
      "32/32 [==============================] - 14s 435ms/step - loss: 0.2253 - acc: 0.9688 - val_loss: 3.7100 - val_acc: 0.6562\n",
      "Epoch 24/100\n",
      "32/32 [==============================] - 14s 432ms/step - loss: 0.2103 - acc: 0.9375 - val_loss: 3.6396 - val_acc: 0.6875\n",
      "Epoch 25/100\n",
      "32/32 [==============================] - 14s 422ms/step - loss: 0.2016 - acc: 0.9062 - val_loss: 3.5588 - val_acc: 0.6875\n",
      "Epoch 26/100\n",
      "32/32 [==============================] - 14s 424ms/step - loss: 0.1954 - acc: 0.9062 - val_loss: 3.4722 - val_acc: 0.6875\n",
      "Epoch 27/100\n",
      "32/32 [==============================] - 13s 419ms/step - loss: 0.1771 - acc: 0.9375 - val_loss: 3.4024 - val_acc: 0.7188\n",
      "Epoch 28/100\n",
      "32/32 [==============================] - 13s 420ms/step - loss: 0.1581 - acc: 0.9375 - val_loss: 3.3542 - val_acc: 0.6562\n",
      "Epoch 29/100\n",
      "32/32 [==============================] - 14s 431ms/step - loss: 0.1337 - acc: 0.9688 - val_loss: 3.3189 - val_acc: 0.6562\n",
      "Epoch 30/100\n",
      "32/32 [==============================] - 14s 427ms/step - loss: 0.1212 - acc: 1.0000 - val_loss: 3.2705 - val_acc: 0.6562\n",
      "Epoch 31/100\n",
      "32/32 [==============================] - 14s 436ms/step - loss: 0.1143 - acc: 1.0000 - val_loss: 3.2204 - val_acc: 0.6250\n",
      "Epoch 32/100\n",
      "32/32 [==============================] - 13s 420ms/step - loss: 0.1131 - acc: 1.0000 - val_loss: 3.1476 - val_acc: 0.6250\n",
      "Epoch 33/100\n",
      "32/32 [==============================] - 13s 422ms/step - loss: 0.1035 - acc: 1.0000 - val_loss: 3.0254 - val_acc: 0.6250\n",
      "Epoch 34/100\n",
      "32/32 [==============================] - 14s 422ms/step - loss: 0.0931 - acc: 1.0000 - val_loss: 2.9037 - val_acc: 0.6250\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-f223befd988e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimages_test2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_test2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_cnn_model_dropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/Final Project/SkinCancerClassifier/py/cnn_classifier.py\u001b[0m in \u001b[0;36mfit_cnn_model_dropout\u001b[0;34m(cnn, loss_param, epoch, batch)\u001b[0m\n\u001b[1;32m    153\u001b[0m                         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m                         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m                         callbacks=[rlrop])\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../saved_models/CNN_Run_1.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/flatiron/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/anaconda3/envs/flatiron/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/flatiron/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/flatiron/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/flatiron/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "images_test2, labels_test2 = fit_cnn_model_dropout(cnn2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0718 18:15:44.591176 4344800704 deprecation_wrapper.py:119] From /anaconda3/envs/flatiron/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0718 18:15:44.592377 4344800704 deprecation_wrapper.py:119] From /anaconda3/envs/flatiron/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0718 18:15:44.594820 4344800704 deprecation_wrapper.py:119] From /anaconda3/envs/flatiron/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0718 18:15:44.611951 4344800704 deprecation_wrapper.py:119] From /anaconda3/envs/flatiron/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0718 18:15:44.631694 4344800704 deprecation_wrapper.py:119] From /anaconda3/envs/flatiron/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W0718 18:15:44.868990 4344800704 deprecation_wrapper.py:119] From /anaconda3/envs/flatiron/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0718 18:15:45.252238 4344800704 deprecation_wrapper.py:119] From /anaconda3/envs/flatiron/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3980: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "W0718 18:15:56.784337 4344800704 deprecation.py:506] From /anaconda3/envs/flatiron/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0718 18:15:56.993060 4344800704 deprecation_wrapper.py:119] From /anaconda3/envs/flatiron/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 7 classes.\n",
      "Found 6415 images belonging to 7 classes.\n",
      "Found 1600 images belonging to 7 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0718 18:15:58.525070 4344800704 deprecation.py:323] From /anaconda3/envs/flatiron/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/20\n",
      "32/32 [==============================] - 12s 386ms/step - loss: 2.6564 - acc: 0.1875 - val_loss: 3.1423 - val_acc: 0.6250\n",
      "Epoch 2/20\n",
      "32/32 [==============================] - 8s 263ms/step - loss: 1.5571 - acc: 0.4375 - val_loss: 2.2597 - val_acc: 0.6562\n",
      "Epoch 3/20\n",
      "32/32 [==============================] - 9s 274ms/step - loss: 1.2633 - acc: 0.5312 - val_loss: 2.2221 - val_acc: 0.6562\n",
      "Epoch 4/20\n",
      "32/32 [==============================] - 9s 270ms/step - loss: 1.1337 - acc: 0.5938 - val_loss: 2.0129 - val_acc: 0.6250\n",
      "Epoch 5/20\n",
      "32/32 [==============================] - 9s 268ms/step - loss: 0.6889 - acc: 0.8438 - val_loss: 1.8433 - val_acc: 0.5938\n",
      "Epoch 6/20\n",
      "32/32 [==============================] - 9s 274ms/step - loss: 0.6562 - acc: 0.8438 - val_loss: 1.6964 - val_acc: 0.5938\n",
      "Epoch 7/20\n",
      "32/32 [==============================] - 9s 270ms/step - loss: 0.2826 - acc: 0.9688 - val_loss: 1.6421 - val_acc: 0.5938\n",
      "Epoch 8/20\n",
      "32/32 [==============================] - 9s 274ms/step - loss: 0.3158 - acc: 0.9375 - val_loss: 1.5878 - val_acc: 0.6250\n",
      "Epoch 9/20\n",
      "32/32 [==============================] - 9s 274ms/step - loss: 0.2178 - acc: 0.9375 - val_loss: 1.5497 - val_acc: 0.6250\n",
      "Epoch 10/20\n",
      "32/32 [==============================] - 9s 271ms/step - loss: 0.1997 - acc: 0.9688 - val_loss: 1.5810 - val_acc: 0.5938\n",
      "Epoch 11/20\n",
      "32/32 [==============================] - 9s 276ms/step - loss: 0.2205 - acc: 0.9062 - val_loss: 1.6323 - val_acc: 0.5938\n",
      "Epoch 12/20\n",
      "32/32 [==============================] - 9s 270ms/step - loss: 0.0520 - acc: 1.0000 - val_loss: 1.6985 - val_acc: 0.5938\n",
      "Epoch 13/20\n",
      "32/32 [==============================] - 9s 272ms/step - loss: 0.0449 - acc: 1.0000 - val_loss: 1.7795 - val_acc: 0.5938\n",
      "Epoch 14/20\n",
      "32/32 [==============================] - 9s 281ms/step - loss: 0.0494 - acc: 1.0000 - val_loss: 1.8683 - val_acc: 0.5938\n",
      "Epoch 15/20\n",
      "32/32 [==============================] - 9s 273ms/step - loss: 0.0462 - acc: 1.0000 - val_loss: 1.9404 - val_acc: 0.5938\n",
      "Epoch 16/20\n",
      "32/32 [==============================] - 9s 273ms/step - loss: 0.0358 - acc: 1.0000 - val_loss: 2.0061 - val_acc: 0.5938\n",
      "Epoch 17/20\n",
      "32/32 [==============================] - 9s 272ms/step - loss: 0.0150 - acc: 1.0000 - val_loss: 2.0364 - val_acc: 0.5938\n",
      "Epoch 18/20\n",
      "32/32 [==============================] - 9s 276ms/step - loss: 0.0443 - acc: 1.0000 - val_loss: 2.0689 - val_acc: 0.5938\n",
      "Epoch 19/20\n",
      "32/32 [==============================] - 9s 271ms/step - loss: 0.0356 - acc: 1.0000 - val_loss: 2.0855 - val_acc: 0.5938\n",
      "Epoch 20/20\n",
      "32/32 [==============================] - 9s 273ms/step - loss: 0.0561 - acc: 0.9688 - val_loss: 2.0577 - val_acc: 0.5312\n"
     ]
    }
   ],
   "source": [
    "model, images_test, labels_test = imagenet_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "32/32 [==============================] - 4s 134ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.3886892795562744, 0.46875]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(images_test, labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a model and plot learning curve\n",
    "def fit_model(trainX, trainy, testX, testy, n_batch):\n",
    "    # define model\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', \n",
    "            input_shape=(450, 600,  3), padding='SAME'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(32, activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Dense(7, activation='softmax'))\n",
    "    \n",
    "    # compile model\n",
    "    opt = SGD(lr=0.01, momentum=0.9)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy']) # fit model\n",
    "    history = model.fit(trainX, trainy, validation_data=(testX, testy), epochs=50,\n",
    "          verbose=0, batch_size=n_batch)\n",
    "      # plot learning curves\n",
    "    plt.plot(history.history['acc'], label='train') \n",
    "    plt.plot(history.history['val_acc'], label='test') \n",
    "    plt.title('batch='+str(n_batch), pad=-40)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 7 classes.\n",
      "Found 6415 images belonging to 7 classes.\n",
      "Found 1600 images belonging to 7 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0719 09:34:08.651354 4498068928 deprecation_wrapper.py:119] From /anaconda3/envs/flatiron/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0719 09:34:08.820673 4498068928 deprecation.py:323] From /anaconda3/envs/flatiron/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# prepare dataset\n",
    "trainX, trainy, testX, testy, validX, validy = split_images()\n",
    "# create learning curves for different batch sizes\n",
    "batch_sizes = [4, 8, 16, 32, 64]\n",
    "for i in range(len(batch_sizes)):\n",
    "  # determine the plot number\n",
    "  plot_no = 420 + (i+1)\n",
    "  plt.subplot(plot_no)\n",
    "  # fit model and plot learning curves for a batch size\n",
    "  fit_model(trainX, trainy, testX, testy, batch_sizes[i])\n",
    "# show learning curves\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
